{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define headers for web requests (to mimic a browser request)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to scrape the Bugis dictionary website\n",
    "def scrape_bahasa_bugis_words(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()  # Raise an exception for any non-200 responses\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Modify these according to the structure of the Bugis website\n",
    "    word_entries = []\n",
    "    entries = soup.find_all('div', class_='word-entry')  # Example: you might need to adjust this selector\n",
    "\n",
    "    for entry in entries:\n",
    "        bugis_word = entry.find('span', class_='bugis-word').get_text(strip=True)\n",
    "        translation = entry.find('span', class_='translation').get_text(strip=True)\n",
    "        word_entries.append({'bugis_word': bugis_word, 'translation': translation})\n",
    "\n",
    "    return word_entries\n",
    "\n",
    "# Function to save words to a CSV file\n",
    "def save_words_to_csv(words, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['bugis_word', 'translation'])\n",
    "        writer.writeheader()\n",
    "        for word in words:\n",
    "            writer.writerow(word)\n",
    "\n",
    "# Function to convert words to a DataFrame for easy inspection\n",
    "def words_to_dataframe(words):\n",
    "    return pd.DataFrame(words)\n",
    "\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "# Notebook code execution example\n",
    "base_url = \"https://www.liputan6.com/hot/read/5187403/70-bahasa-bugis-dan-artinya-dari-kosakata-hingga-contoh-kalimatnya?page=\"  # Replace with the actual URL\n",
    "all_words = []\n",
    "\n",
    "# Scrape multiple pages if needed\n",
    "for page_num in range(1, 8):  # Adjust range according to the number of pages available\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    url = f\"{base_url}{page_num}\"\n",
    "    words = scrape_bahasa_bugis_words(url)\n",
    "    all_words.extend(words)\n",
    "    time.sleep(random.uniform(1, 3))  # Sleep between requests to avoid being blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete and saved to bahasa_bugis_words.csv!\n"
     ]
    }
   ],
   "source": [
    "# Convert scraped words to DataFrame for inspection\n",
    "words_df = words_to_dataframe(all_words)\n",
    "display(words_df)  # Use this to visually inspect the DataFrame in a notebook\n",
    "\n",
    "# Save all the collected words to a CSV file\n",
    "save_words_to_csv(all_words, 'bahasa_bugis_words.csv')\n",
    "print(\"Scraping complete and saved to bahasa_bugis_words.csv!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
